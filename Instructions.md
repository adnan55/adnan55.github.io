SYSTEM INSTRUCTIONS: Portfolio Expansion for AutoArchitect.me
Target: Existing Website Framework Source Data: Performance Reports (Dec 2025 â€“ Feb 2026) Tone: Technical, Architectural, Logic-Focused.

ðŸ—ï¸ SECTION 01: Project Showcase (The Architectâ€™s Blueprints)
Instruction for AI: Do not list project names. Instead, create three "Logic Archetype" cards that describe the technical hurdles overcome.

Project Archetype A: The "Resilient Crawler" (High-Uptime Data Engineering)
Logic Applied: Implemented Systematic Checkpointing for long-running (25hr+) extractions to prevent data loss during power outages or server timeouts.

The Innovation: Developed a "Download-First, Parse-Local" architecture, reducing server-side interaction time by 50% and bypassing "Headless" detection by simulating mobile-device API calls when desktop security was too high.

Complexity: Successfully navigated obfuscated/non-semantic HTML classes and used Selenium/ChromeDriver to bypass advanced anti-bot measures.

Project Archetype B: The "Vision Sentinel" (Automated Visual QA)
Logic Applied: Utilized OpenCV and Scikit-Image to create a structural similarity comparison engine.

The Innovation: Built an automated Hallucination Detector for AI-generated images. Instead of manual review, the system algorithmically categorizes images into "Perfect," "Mismatched," or "Hallucinated" based on pixel-variance.

Scale: Managed a production pipeline that generated 50,000+ unique prompts, pivoting from abstract imagination to "Real-Life Object" logic to increase model accuracy.

Project Archetype C: The "Archetype Cloner" (AI-Powered Code Reuse)
Logic Applied: Used Gemini CLI to analyze and summarize DOM structures across 60+ unique domains.

The Innovation: Identified "Replicas" (websites with identical UI architectures). Instead of writing 60 scripts, I cloned and adapted core logic for "Archetypes," reducing development time for new sites to under 30 minutes.

ðŸ“ SECTION 02: The "System Log" Blog Series
Instruction for AI: Generate a "Blog" section styled as a Terminal File Directory (/mnt/logs/docs/). Each post should follow the "Log Entry" format.

Log_001: The 25-Hour Extraction Problem
Context: How to maintain data integrity when scraping 228,000+ variants over multiple days.

Key Takeaway: The importance of building checkpoint-based persistence in Python scripts to handle hardware/network failures without restarting from zero.

Log_002: Computer Vision vs. Human Fatigue
Context: Why I built a bot to do my Quality Control.

Key Takeaway: Using SSIM (Structural Similarity Index) to catch tiny visual differences that the human eye misses after 10 minutes of work.

Log_003: The Mobile-First Pivot
Context: Bypassing high-security desktop sites.

Key Takeaway: When desktop browsers get blocked, pivoting to Mobile API Simulation is the "silver bullet" for data extraction.

Log_004: Local RAG & Data Privacy
Context: Building a local Retrieval-Augmented Generation (RAG) system.

Key Takeaway: Using Ollama (Gemma 3) and local embedding models to process sensitive internal documentation without sending data to the cloud.

ðŸ› ï¸ SECTION 03: Updated Tech Stack (Inventory)
Instruction for AI: Use these specific tools for the "Toolbelt" section.

Automation: Selenium, BeautifulSoup, n8n, Batch Scripting.

AI/ML: Gemini CLI, OpenAI Batch API, Prompt Engineering, RAG (Ollama).

Vision: OpenCV, Scikit-Image, ComfyUI, Stable Diffusion.

Data: MySQL, CSV Transformation, Regex Logic, Mobile API Simulation.

ðŸš€ FINAL UI INSTRUCTIONS FOR ANTIGRAVITY
Terminal Feed: Integrate the "Activity Snapshot" metrics (54+ lists scraped, 50k prompts generated) into a scrolling live feed in the header.

Logic Flowcards: When a visitor hovers over a project, show a Mermaid.js flowchart showing the "Input -> Checkpoint -> Local HTML -> Validated CSV" logic.

Status Indicator: Set the "Last Updated" timestamp to the most recent log date (February 2026) to show the site is active.